#### 什么是大型语言模型？

大型语言模型（LLM）是基于大量数据进行预训练的超大型深度学习模型。底层转换器是一组神经网络，这些神经网络由具有自注意力功能的编码器和解码器组成。编码器和解码器从一系列文本中提取含义，并理解其中的单词和短语之间的关系。

转换器 LLM 能够进行无监督的训练，但更精确的解释是转换器可以执行自主学习。通过此过程，转换器可学会理解基本的语法、语言和知识。

与早期按顺序处理输入的循环神经网络（RNN）不同，转换器并行处理整个序列。这可让数据科学家使用 GPU 训练基于转换器的 LLM，从而大幅度缩短训练时间。

借助转换器神经网络架构，您可使用非常大规模的模型，其中通常具有数千亿个参数。这种大规模模型可以摄取通常来自互联网的大量数据，但也可以从包含 500 多亿个网页的 Common Crawl 和拥有约 5700 万个页面的 Wikipedia 等来源摄取数据。


#### 大型语言模型工作原理

LLM 通过利用深度学习技术和大量文本数据来运行。这些模型通常基于转换器架构，如生成式预训练转换器，它擅长处理文本输入等顺序数据。LLM 由多层神经网络组成，每层神经网络的参数都可以在训练过程中进行微调，而被称为注意力机制的众多神经网络层则进一步增强了这些神经网络的功能，这些神经网络层可以对数据集的特定部分进行调整。

在训练过程中，这些模型学习根据前面单词提供的上下文来预测句子中的下一个单词。该模型通过将概率分数归因于重复的已标记单词（分解为较小的字符序列）来实现这一点。然后，这些标记被转换为嵌入，嵌入是该上下文的数字表示。

为了确保准确性，这个过程涉及在大量文本语料库（数十亿页）上训练 LLM，使 LLM 能够通过零样本和自我监督学习来学习语法、语义和概念关系。经过这些训练数据的训练后，LLM 就可以根据它们收到的输入自动预测下一个单词，并利用它们获得的模式和知识来生成文本。其结果是生成连贯且与上下文相关的语言，可用于广泛的 NLU 和内容生成任务。

还可以通过即时工程、即时调优、微调和其他策略来提高模型性能，例如基于人类反馈的强化学习 (RLHF)，以消除偏见、仇恨言论和被称为“幻觉”的事实错误答案，这些通常是对如此多的非结构化数据进行训练的有害副产品。这是确保企业级 LLM 随时可用，不会使组织承担不必要的责任或对组织声誉造成损害的最重要的方面之一。

#### LLM 用例

LLM 正在重新定义越来越多的业务流程，并已在各个行业的无数用例和任务中证明了它们的多功能性。LLM 可以增强聊天机器人和虚拟助理（例如 IBM watsonx Assistant 和 Google 的 BARD）中的会话式 AI，以增强支持卓越客户服务的交互，提供模仿与人工客服交互的情境感知响应。

LLM 还擅长内容生成，可以自动创建内容，包括博客文章、营销或销售资料以及其他写作任务。在研究和学术界，它们帮助从大量数据集中总结和提取信息，加速知识发现。LLM 在语言翻译中也发挥着至关重要的作用，通过提供准确且与上下文相关的翻译来打破语言障碍。它们甚至可以用来编写代码，或者在编程语言之间进行“翻译”。

此外，它们还通过提供文字转语音应用以及以无障碍格式生成内容等功能，帮助残障人员，为无障碍访问功能做出了贡献。从医疗保健到金融，LLM 正在通过简化流程、改善客户体验以及实现更高效和数据驱动的决策来推动行业发展和变革。

最令人兴奋的是，所有这些功能都很容易访问，在某些情况下，实际上只需 API 集成即可。

以下是 LLM 为组织带来益处的一些最重要的领域：

* 文本生成：语言生成能力，如根据提示撰写电子邮件、博客文章或其他中长篇内容，并加以提炼和润色。检索增强生成 (RAG) 就是一个很好的例子。

* 内容摘要：将长文章、新闻报道、研究报告、公司文档甚至客户历史记录汇总成根据输出格式定制长度的完整文本。

* AI 助手：聊天机器人，可以回答客户询问、执行后端任务并以自然语言提供详细信息，作为集成式自助客户服务解决方案的一部分。

* 代码生成：帮助开发人员构建应用程序，查找代码中的错误并发现多种编程语言中的安全问题，甚至在它们之间进行“翻译”。

* 情感分析：分析文本，确定客户的语气，以便大规模了解客户反馈并帮助进行品牌声誉管理。

* 语言翻译：通过流畅的翻译和多语言功能，为各语言和地域的组织提供更广泛的覆盖范围。

LLM 将通过实现客户自助服务自动化、加快对越来越多任务的响应以及提高准确性、增强路由和智能上下文收集，影响从金融到保险、人力资源到医疗保健等各个行业。

#### 增加大语言模型推理能力的方案

目前，推理的方案与构建通用大型语言模型和聊天机器人的方案密切相关。总共有三个阶段：

- 预训练或持续训练：在这个阶段，我们通常在大型数据集（如科学文献或代码数据）上训练大型模型。
- 有监督微调：在这个阶段，我们对模型进行微调，以便完成复杂任务的指令。
- 强化学习：在这个阶段，我们使用诸如任务是否已全部/部分完成的信号作为奖励。

因此，在我们的文献分析中，我们同时考虑推理和编码。我们将看到，就学习方法而言，这两者之间存在惊人的相关性。

* 预训练与持续训练

分析以下几项研究：

1. Lewkowycz et. al. 2022. Minerva: [Solving Quantitative Reasoning Problems with Language Models](https://arxiv.org/abs/2206.14858)

* 在来自 Arxiv 论文的 38.5B 的 token 上继续训练 PaLM 540B。 
* 在 MATH （一个需要使用 LaTeX 格式回答问题的困难数据集），上的得分为 33.6（[GPT-4 的得分是 42.5](https://github.com/FranxYao/chain-of-thought-hub)）

2. Taylor et. al. 2022. [Galactica: A Large Language Model for Science](https://arxiv.org/abs/2211.09085)

* 在包含论文、代码、参考资料、知识库和其他内容的 106B token 上预训练一个120B语言模型。
* 在MATH上的表现为 20.4（Minerva 33.6，GPT-4 42.5） 
 
3. Chen et. al. 2021. [Codex: Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374)

* 在159GB代码数据上继续训练 12B GPT-3 模型，提高了 HumanEval 数据集上的代码性能。

这些研究发现，在大量科学文献代码上进行训练可以显著提高基础模型的推理编码能力。